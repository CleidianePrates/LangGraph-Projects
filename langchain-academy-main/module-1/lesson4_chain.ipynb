{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cbf2458",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/chain.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58238466-lesson-4-chain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee55d3da-c53a-4c76-b46f-8e0d602e072e",
   "metadata": {},
   "source": [
    "# Chain\n",
    "\n",
    "## Revisão\n",
    "\n",
    "Construímos um graph simples com nodes, normal edges e conditional edges.\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "Agora, vamos construir até uma chain simples que combina 4 [concepts](https://python.langchain.com/v0.2/docs/concepts/):\n",
    "\n",
    "* Uso de [chat messages](https://python.langchain.com/v0.2/docs/concepts/#messages) como nosso graph state\n",
    "* Uso de [chat models](https://python.langchain.com/v0.2/docs/concepts/#chat-models) em graph nodes\n",
    "* [Binding tools](https://python.langchain.com/v0.2/docs/concepts/#tools) ao nosso chat model\n",
    "* [Executing tool calls](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling) em graph nodes\n",
    "\n",
    "![Screenshot 2024-08-21 at 9.24.03 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dd607b08df5e1101_chain1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a55e2e80-a718-4aaf-99b9-371157b34a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ac2d0-c7b0-4a20-86e5-4b6ed15ec20e",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "Chat models podem usar [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages), que capturam diferentes roles dentro de uma conversa.\n",
    "\n",
    "LangChain suporta vários tipos de message, incluindo `HumanMessage`, `AIMessage`, `SystemMessage` e `ToolMessage`.\n",
    "\n",
    "Estas representam uma mensagem do usuário, do chat model, para o chat model instruir comportamento, e de uma tool call.\n",
    "\n",
    "Vamos criar uma lista de messages.\n",
    "\n",
    "Cada message pode ser fornecida com algumas coisas:\n",
    "\n",
    "* `content` - conteúdo da mensagem\n",
    "* `name` - opcionalmente, um autor da mensagem\n",
    "* `response_metadata` - opcionalmente, um dict de metadados (por exemplo, frequentemente preenchido pelo provedor do modelo para `AIMessages`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866b5321-a238-4a9e-af9e-f11a131b5f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "So you said you were researching ocean mammals?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "Yes, that's right.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Great, what would you like to learn about.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "I want to learn about the best place to see Orcas in the US.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"Yes, that's right.\",name=\"Lance\"))\n",
    "messages.append(AIMessage(content=f\"Great, what would you like to learn about.\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn about the best place to see Orcas in the US.\", name=\"Lance\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca48df0-b639-4ff1-a777-ffe2185d991e",
   "metadata": {},
   "source": [
    "## Chat Models\n",
    "\n",
    "[Chat models](https://python.langchain.com/v0.2/docs/concepts/#chat-models) podem usar uma sequência de message como input e suportar tipos de message, como discutido acima.\n",
    "\n",
    "Existem [muitos](https://python.langchain.com/v0.2/docs/concepts/#chat-models) para escolher! Vamos trabalhar com OpenAI.\n",
    "\n",
    "Vamos verificar se sua `OPENAI_API_KEY` está configurada e, se não estiver, você será solicitado a inseri-la."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2652d5ec-7602-4220-bc6e-b90783ab287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae53d4-14f5-4bf3-a953-cc465240f5b5",
   "metadata": {},
   "source": [
    "Podemos carregar um chat model e invocá-lo com nossa lista de messages.\n",
    "\n",
    "Podemos ver que o resultado é uma `AIMessage` com `response_metadata` específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b99ad4-5753-49d3-a916-a9e949722c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "result = llm.invoke(messages)\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d60338-c892-4d04-a83f-878de4a76a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The Pacific Northwest, particularly the waters around the San Juan Islands in Washington State, is one of the best places in the United States to see orcas, also known as killer whales, in the wild. \\n\\nThe San Juan Islands are located in the Salish Sea, which is home to several pods of Southern Resident orcas. These islands provide a natural habitat for orcas due to the abundance of salmon, their primary food source. Orca sightings are most common between May and October, which is the peak season for whale watching.\\n\\nThere are numerous whale-watching tours available in the area that offer a chance to see these magnificent creatures up close while emphasizing responsible and sustainable wildlife viewing practices.\\n\\nIn addition to the San Juan Islands, other locations along the West Coast, such as the waters near Seattle and the Olympic Peninsula, also offer opportunities to observe orcas in their natural environment.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 177, 'prompt_tokens': 67, 'total_tokens': 244, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f5bdcc3276', 'id': 'chatcmpl-BWYkyz3nl0JAQRLyx8a3UCmXHpV8Z', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--fc1b350b-03f2-43ab-846f-419230df5aa7-0', usage_metadata={'input_tokens': 67, 'output_tokens': 177, 'total_tokens': 244, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3a29654-6b8e-4eda-9cec-22fabb9b8620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 177,\n",
       "  'prompt_tokens': 67,\n",
       "  'total_tokens': 244,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-4o-2024-08-06',\n",
       " 'system_fingerprint': 'fp_f5bdcc3276',\n",
       " 'id': 'chatcmpl-BWYkyz3nl0JAQRLyx8a3UCmXHpV8Z',\n",
       " 'service_tier': 'default',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response_metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4718bd5c-5314-4405-a164-f1fe912ae306",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Tools são úteis sempre que você deseja que um modelo interaja com sistemas externos.\n",
    "\n",
    "Sistemas externos (por exemplo, APIs) frequentemente requerem um schema de entrada ou payload específico, em vez de linguagem natural.\n",
    "\n",
    "Quando vinculamos uma API, por exemplo, como uma tool, damos ao modelo conhecimento do schema de entrada necessário.\n",
    "\n",
    "O modelo escolherá chamar uma tool com base na entrada em linguagem natural do usuário.\n",
    "\n",
    "E retornará uma saída que adere ao schema da tool.\n",
    "\n",
    "[Muitos provedores de LLM suportam tool calling](https://python.langchain.com/v0.1/docs/integrations/chat/) e a [interface de tool calling](https://blog.langchain.dev/improving-core-tool-interfaces-and-docs-in-langchain/) no LangChain é simples.\n",
    "\n",
    "Você pode simplesmente passar qualquer `function` Python para `ChatModel.bind_tools(function)`.\n",
    "\n",
    "![Screenshot 2024-08-19 at 7.46.28 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dc1c17a7a57f9960_chain2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a942b1",
   "metadata": {},
   "source": [
    "Vamos mostrar um exemplo simples de tool calling!\n",
    "\n",
    "A função `multiply` é nossa tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "928faf56-1a1a-4c5f-b97d-bd64d8e166d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3f9dba",
   "metadata": {},
   "source": [
    "Se passarmos um input - por exemplo, `\"What is 2 multiplied by 3\"` - vemos um tool call retornado.\n",
    "\n",
    "O tool call tem arguments específicos que correspondem ao schema de input da nossa function, junto com o name da function a ser chamada.\n",
    "\n",
    "```\n",
    "{'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9edbe13e-cc72-4685-ac97-2ebb4ceb2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 2 multiplied by 3\", name=\"Lance\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a78178cb-fa43-45b5-be5e-5a22bda5a5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 2, 'b': 3},\n",
       "  'id': 'call_66zSQwocT2cGFjX7EL24kg8G',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c10f9a-2372-486b-9305-55b7c41ecd6e",
   "metadata": {},
   "source": [
    "## Usando messages como state\n",
    "\n",
    "Com essas fundações estabelecidas, agora podemos usar [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages) em nosso graph state.\n",
    "\n",
    "Vamos definir nosso state, `MessagesState`, como um `TypedDict` com uma única key: `messages`.\n",
    "\n",
    "`messages` é simplesmente uma lista de messages, como definimos acima (por exemplo, `HumanMessage`, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3699dd5c-398c-43c7-b496-fd87e55e11ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211cba3e-ebba-4b91-a539-1cbc28b4a40e",
   "metadata": {},
   "source": [
    "## Reducers\n",
    "\n",
    "Agora, temos um pequeno problema!\n",
    "\n",
    "Como discutimos, cada node retornará um novo valor para nossa state key `messages`.\n",
    "\n",
    "Mas este novo valor [substituirá](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) o valor anterior de `messages`.\n",
    "\n",
    "Conforme nosso graph é executado, queremos **anexar** messages à nossa state key `messages`.\n",
    "\n",
    "Podemos usar [reducer functions](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) para resolver isso.\n",
    "\n",
    "Reducers nos permitem especificar como as atualizações de state são realizadas.\n",
    "\n",
    "Se nenhuma reducer function for especificada, assume-se que as atualizações para a key devem *substituí-la* como vimos antes.\n",
    "\n",
    "Mas, para anexar messages, podemos usar o reducer pré-construído `add_messages`.\n",
    "\n",
    "Isso garante que quaisquer messages sejam anexadas à lista existente de messages.\n",
    "\n",
    "Simplesmente precisamos anotar nossa key `messages` com a reducer function `add_messages` como metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b33eb72-3197-4870-b9a3-0da8056c40c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3663e574-ba15-46be-a37c-48c8052d693b",
   "metadata": {},
   "source": [
    "Since having a list of messages in graph state is so common, LangGraph has a pre-built [`MessagesState`](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate)! \n",
    "\n",
    "`MessagesState` is defined: \n",
    "\n",
    "* With a pre-build single `messages` key\n",
    "* This is a list of `AnyMessage` objects \n",
    "* It uses the `add_messages` reducer\n",
    "\n",
    "We'll usually use `MessagesState` because it is less verbose than defining a custom `TypedDict`, as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ab516ee-eab1-4856-8210-99f1fe499672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    # Add any keys needed beyond messages, which is pre-built \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0fff7-60a2-4582-8f12-3a3ab6633d6c",
   "metadata": {},
   "source": [
    "To go a bit deeper, we can see how the `add_messages` reducer works in isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23ffea76-16a5-4053-a1bc-91e0101d91dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='7b6f828d-967d-4269-99ce-4a262e016a38'),\n",
       " HumanMessage(content=\"I'm looking for information on marine biology.\", additional_kwargs={}, response_metadata={}, name='Lance', id='e220b2c6-04be-4570-ae8f-5cffe632bdd6'),\n",
       " AIMessage(content='Sure, I can help with that. What specifically are you interested in?', additional_kwargs={}, response_metadata={}, name='Model', id='9ff3049d-58e1-4924-b012-3cb84f12a9d4')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial state\n",
    "initial_messages = [AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "                    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Lance\")\n",
    "                   ]\n",
    "\n",
    "# New message to add\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "# Test\n",
    "add_messages(initial_messages , new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485adccc-f262-49dd-af4f-a30e9b6a48e2",
   "metadata": {},
   "source": [
    "## Our graph\n",
    "\n",
    "Now, lets use `MessagesState` with a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5306639-7e6a-44be-8471-8d2631701cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "    \n",
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8909771-7786-47d6-a53d-6bbc3b365737",
   "metadata": {},
   "source": [
    "If we pass in `Hello!`, the LLM responds without any tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "983e2487-c0a5-40a2-afbc-aa53ff49fefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi there! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Hello!\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588688b-efd9-4dbc-abf2-7903e3ef89ba",
   "metadata": {},
   "source": [
    "The LLM chooses to use a tool when it determines that the input or task requires the functionality provided by that tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fe8b042-ecc8-426f-995e-cc1bbaf7cacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_O09eas0nzxvRHX4iPNEFCtFD)\n",
      " Call ID: call_O09eas0nzxvRHX4iPNEFCtFD\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Multiply 2 and 3\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fbae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
